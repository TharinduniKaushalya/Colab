{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNStRmohXvYhNqabp0f2jnn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TharinduniKaushalya/Colab/blob/main/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GibHimqEzH5B"
      },
      "source": [
        "!pip install tensorflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAInpEBLw4ks",
        "outputId": "1d155c10-3e99-4ca5-d858-d38526a7012a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import keras\n",
        "print('keras: %s' % keras.__version__)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "keras: 2.4.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qakQLAYN43qF"
      },
      "source": [
        "import theano as th\n",
        "import h5py\n",
        "from keras.models import model_from_json\n",
        "import pickle\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import svm\n",
        "\n",
        "### General imports ###\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time\n",
        "from time import sleep\n",
        "import seaborn as sns\n",
        "import re\n",
        "import os\n",
        "import argparse\n",
        "from collections import OrderedDict\n",
        "import matplotlib.animation as animation\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "### Image processing ###\n",
        "from scipy.ndimage import zoom\n",
        "from scipy.spatial import distance\n",
        "import imutils\n",
        "from scipy import ndimage\n",
        "import cv2\n",
        "import dlib\n",
        "from __future__ import division\n",
        "from imutils import face_utils"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEOs8omr74Ci"
      },
      "source": [
        "pip install --upgrade keras\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gJ0tW3w8uek"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import itertools\n",
        "import os\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhkvunU62oYw"
      },
      "source": [
        "import tensorflow.keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, SeparableConv2D\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, SeparableConv2D, ZeroPadding2D, UpSampling2D, BatchNormalization, Input, GlobalAveragePooling2D, AveragePooling2D\n",
        "#from tensorflow. keras.utils import np_utils\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import SGD, RMSprop\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras import models\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from tensorflow.keras.layers import Input, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.applications import densenet\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYZnNKMXxJha"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation,Flatten, BatchNormalization\n",
        "from keras.layers import MaxPool2D,Conv2D\n",
        "import os"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNlQMBYpzi3I",
        "outputId": "530b2f1e-40e8-4b68-c1af-4fe8d1805112",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "num_classes = 6\n",
        "img_rows,img_cols = 48,48\n",
        "batch_size=8\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGgesQoxxRKg"
      },
      "source": [
        "X_train = r\"https://drive.google.com/drive/folders/1GI4vXSWIDVbWp6ZZvalzvpUCmQXqjdzm?usp=sharing\"\n",
        "y_train = r\"https://drive.google.com/drive/folders/1wlCDDU3WOcQM5g3v1MssRWsyxJMCPYKR?usp=sharing\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AuuA5bzyCp7"
      },
      "source": [
        "xTrain2 = (\"drive/My Drive/images/train\")\n",
        "yTrain2 = (\"drive/My Drive/images/validation\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGFPP0W31oke"
      },
      "source": [
        "train_Scale= ImageDataGenerator(rescale=1./255,rotation_range=30,shear_range=0.3,zoom_range=0.3,height_shift_range=0.3,width_shift_range=0.3,horizontal_flip=True,vertical_flip=True)\n",
        "vali_Scale= ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtmkbrzR4AQo",
        "outputId": "4f3703e6-a6f8-48cd-eafa-f19cab08c339",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_generator = train_Scale.flow_from_directory (xTrain2,color_mode='grayscale',target_size=(img_rows,img_rows),batch_size=batch_size,class_mode='categorical',shuffle=True)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 28821 images belonging to 7 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGuz6UVX65Vh",
        "outputId": "23c456a7-da63-4cd8-ca64-0a46d7a57a97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "vali_generator= vali_Scale.flow_from_directory (yTrain2,color_mode='grayscale',target_size=(img_rows,img_rows),batch_size=batch_size,class_mode='categorical',shuffle=True)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 7080 images belonging to 7 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5TElS-KzfGP"
      },
      "source": [
        "model = Sequential()\n",
        "\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RR32wCRc1Z2x"
      },
      "source": [
        "model.add(Conv2D(32,(3,3),padding='same', kernel_initializer='he_normal'))\n",
        "model.add(Activation('elu'))\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 57,
      "outputs": []
    }
  ]
}